{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ae230d7-2ab1-469e-a6a0-238293c1eeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d680460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY\n",
      "PROXYCURL_API_KEY\n",
      "TAVILY_API_KEY\n",
      "LANGCHAIN_TRACING_V2\n",
      "LANGCHAIN_ENDPOINT\n",
      "LANGCHAIN_API_KEY\n",
      "LANGCHAIN_PROJECT\n"
     ]
    }
   ],
   "source": [
    "env_vars = dotenv_values()\n",
    "for key in env_vars.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042c85b-397e-45fd-92ff-3177d182c1cb",
   "metadata": {},
   "source": [
    "# 1. OpenAI: Chat API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a5d7ff",
   "metadata": {},
   "source": [
    "En este apartado vamos a se llama a la API de OpenAI directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9fac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09214c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BUZrssXxWHgbTF1e3GVIMMK3ZBtE2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1+1 equals 2.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1746627416, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=14, total_tokens=22, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar el cliente\n",
    "client = OpenAI()\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 1+1?\"}]\n",
    "    \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7029b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e4a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(\"What is 1+1?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0d8b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone.\n",
      "\n",
      "text: ```Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_email = \"\"\"Arrr, I be fuming that me blender lid flew off and \\\n",
    "splattered me kitchen walls with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\"\"\"\n",
    "\n",
    "style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text that is delimited by triple backticks into a \\\n",
    "style that is {style}.\n",
    "\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4733f3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c74f4a",
   "metadata": {},
   "source": [
    "# LangChain: Chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a22bf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b140df4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1030a966d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1030e86790>, root_client=<openai.OpenAI object at 0x7f1030e87c10>, root_async_client=<openai.AsyncOpenAI object at 0x7f1030a96bd0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dadea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "template_string = \"\"\"Translate the text that is delimited by triple backticks into a \\\n",
    "style that is {style}.\n",
    "\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0206e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['customer_email', 'style'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['customer_email', 'style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}.\\n\\ntext: ```{customer_email}```\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a30e830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['customer_email', 'style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}.\\n\\ntext: ```{customer_email}```\\n')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d3a49a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_email', 'style']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ce1c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"Arrr, I be fuming that me blender lid flew off and \\\n",
    "splattered me kitchen walls with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\"\"\"\n",
    "\n",
    "customer_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style,\n",
    "    customer_email=customer_email\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f363829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone.\\n\\ntext: ```Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!```\\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bf2683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ab821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "721168c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac28d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887270a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e9ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9ce45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269c248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea4a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploring-langchain",
   "language": "python",
   "name": "exploring-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
