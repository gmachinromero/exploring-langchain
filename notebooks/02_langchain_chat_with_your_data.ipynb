{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ae230d7-2ab1-469e-a6a0-238293c1eeb1",
   "metadata": {},
   "source": [
    "# 0 - Librer√≠as y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99484c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Librer√≠as\n",
    "# ------------------------------------------------------------------------------\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d680460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY\n",
      "PROXYCURL_API_KEY\n",
      "TAVILY_API_KEY\n",
      "LANGCHAIN_TRACING_V2\n",
      "LANGCHAIN_ENDPOINT\n",
      "LANGCHAIN_API_KEY\n",
      "LANGCHAIN_PROJECT\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "# ------------------------------------------------------------------------------\n",
    "env_vars = dotenv_values()\n",
    "for key in env_vars.keys():\n",
    "    print(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9e5aaaa",
   "metadata": {},
   "source": [
    "# 1 - Introducci√≥n a los RAG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85b775e8",
   "metadata": {},
   "source": [
    "RAG significa Retrieval-Augmented Generation, o Generaci√≥n Aumentada por Recuperaci√≥n. Es una arquitectura h√≠brida que combina LLMs con motores de recuperaci√≥n de informaci√≥n, generalmente basados en embeddings y b√∫squeda vectorial.\n",
    "\n",
    "La idea clave es no depender solo del conocimiento interno del LLM, sino complementarlo con informaci√≥n externa relevante que se recupera en tiempo real desde una base de datos documental."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd86aae8",
   "metadata": {},
   "source": [
    "**¬øPor qu√© usar RAG?**\n",
    "\n",
    "Los modelos generativos, aunque son muy potentes, tienen tres limitaciones clave:\n",
    "- Alucinaciones: inventan respuestas cuando no saben algo.\n",
    "- Obsolescencia: su conocimiento est√° limitado al momento en que fueron entrenados.\n",
    "- Coste de fine-tuning: actualizar su conocimiento requiere reentrenar o usar t√©cnicas m√°s complejas.\n",
    "\n",
    "RAG soluciona esto al buscar primero informaci√≥n en una base de datos externa (documentos, PDFs, p√°ginas web, etc.), y luego pasar esa informaci√≥n como contexto al modelo LLM, que produce una respuesta m√°s precisa, basada en datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d85ab2",
   "metadata": {},
   "source": [
    "**¬øC√≥mo funciona RAG? (flujo t√≠pico)**\n",
    "\n",
    "Un sistema RAG moderno, como el que puedes construir con LangChain, suele organizarse en las siguientes etapas:\n",
    "\n",
    "- Load (Carga de documentos): Se ingestan las fuentes de informaci√≥n que van a alimentar al sistema. El objetivo es leer los datos en bruto y convertirlos en texto plano.\n",
    "- Split (Segmentaci√≥n de texto): Los textos se dividen en fragmentos m√°s peque√±os para facilitar su uso como contexto. Se usan t√©cnicas de ventana deslizante con solapamiento para preservar la coherencia sem√°ntica.\n",
    "- Storage (Vectorizaci√≥n y almacenamiento): Cada fragmento se convierte en un embedding y se almacena en una base vectorial para b√∫squedas por similitud sem√°ntica.\n",
    "- Retrieval (Recuperaci√≥n): La consulta del usuario se vectoriza y se buscan los fragmentos m√°s similares en la base vectorial. Estos fragmentos forman el contexto que se pasar√° al modelo generativo.\n",
    "- Output (Generaci√≥n de respuesta):Se combinan el contexto recuperado y la consulta original, y se pasan al modelo de lenguaje, que genera una respuesta informada.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0298aac8",
   "metadata": {},
   "source": [
    "![](../img/RAG.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f4e4db3",
   "metadata": {},
   "source": [
    "# 2 - Document Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34848d07",
   "metadata": {},
   "source": [
    "El primer paso en cualquier sistema RAG es **ingestar los documentos que contienen el conocimiento base**. En LangChain, esta tarea se gestiona mediante los **loaders**, que permiten leer datos desde m√∫ltiples formatos y fuentes (PDFs, Word, Markdown, HTML, p√°ginas web, etc.).\n",
    "\n",
    "El objetivo es transformar estas fuentes heterog√©neas en una representaci√≥n uniforme: una lista de objetos `Document`, cada uno con su contenido de texto y metadatos asociados.\n",
    "\n",
    "LangChain ofrece una interfaz com√∫n para todos los loaders, lo que facilita trabajar con diferentes tipos de datos sin tener que preocuparte por los detalles de bajo nivel.\n",
    "\n",
    "> A partir de aqu√≠, el texto ya puede ser segmentado y convertido en embeddings para la recuperaci√≥n sem√°ntica.\n",
    "\n",
    "En esta secci√≥n exploraremos c√≥mo utilizar algunos de los loaders m√°s comunes y c√≥mo inspeccionar el resultado de la carga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3f5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, WebBaseLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "507c26d3",
   "metadata": {},
   "source": [
    "## 2.1. - PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c166a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar PDFLoader\n",
    "loader = PyPDFLoader(\"../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "\n",
    "# Cargar PDF\n",
    "pages = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b27eae2e",
   "metadata": {},
   "source": [
    "Cada p√°gina es un `Document` de LangChain, y cada `Document` contiene:\n",
    "- contenido: `page_content`\n",
    "- metadata: `metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a058d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P√°ginas del PDF: 22\n"
     ]
    }
   ],
   "source": [
    "print(f\"P√°ginas del PDF: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f0f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': '../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}, page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we\\'ll start to talk a bit about machine learning.  \\nBy way of introduction, my name\\'s Andrew Ng and I\\'ll be instructor for this class. And so \\nI personally work in machine learning, and I\\'ve worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I\\'m actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learning and all aspects of machine learning. Paul Baumstarck \\nworks in machine learning and computer vision. Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computational biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is the head TA ‚Äî he\\'s head TA two years \\nin a row now ‚Äî works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is ‚Äî I guess he\\'s not here  ‚Äî Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much better throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find learning algorithms to problems \\nin computer vision and biology and robots and language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in computer systems or databases to economists \\nand sort of also an unending stream of people from industry coming to Stanford \\ninterested in applying machine learning methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \\nin \"Computer World\" about the 12 IT skills that employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirable skills in all of IT and all of information technology, and \\ntopping the list was actually machine learning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learning algorithms is one of the things that \\ntouches many areas of science and industries, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from EE? Oh, okay, maybe about a fifth. How')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pages[0]\n",
    "\n",
    "print(type(page))\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d18bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': '../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21b6c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we\\'ll start to talk a bit about machine learning.  \\nBy way of introduction, my name\\'s Andrew Ng and I\\'ll be instructor for this class. And so \\nI personally work in machine learning, and I\\'ve worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I\\'m actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learning and all aspects of machine learning. Paul Baumstarck \\nworks in machine learning and computer vision. Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computational biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is the head TA ‚Äî he\\'s head TA two years \\nin a row now ‚Äî works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is ‚Äî I guess he\\'s not here  ‚Äî Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much better throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find learning algorithms to problems \\nin computer vision and biology and robots and language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in computer systems or databases to economists \\nand sort of also an unending stream of people from industry coming to Stanford \\ninterested in applying machine learning methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \\nin \"Computer World\" about the 12 IT skills that employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirable skills in all of IT and all of information technology, and \\ntopping the list was actually machine learning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learning algorithms is one of the things that \\ntouches many areas of science and industries, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from EE? Oh, okay, maybe about a fifth. How'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff89b7",
   "metadata": {},
   "source": [
    "## 2.2. URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e006ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar WebLoader\n",
    "loader = WebBaseLoader(\"https://raw.githubusercontent.com/gmachinromero/exploring-langchain/refs/heads/master/README.md\")\n",
    "\n",
    "# Cargar URL\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b25a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00216728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://raw.githubusercontent.com/gmachinromero/exploring-langchain/refs/heads/master/README.md'}, page_content='# Exploring LangChain! ü¶úÔ∏èüîó\\n\\nEste repositorio contiene diversas pruebas y experimentos realizados para aprender y explorar las capacidades del framework [LangChain](https://langchain.com/). Aqu√≠ encontrar√°s ejemplos de c√≥mo utilizar las distintas herramientas que proporciona LangChain para la creaci√≥n de aplicaciones basadas en inteligencia artificial, flujos de trabajo y manejo de grandes lenguajes de modelo (LLM).\\n\\n\\n## Contenido\\n\\nEl contenido del repositorio permite ejecutar diferentes scripts de Python con el framework de Langchain con la idea de explorar:\\n- Utilizar LLM tanto de forma online como en local\\n- Conexiones a APIs\\n- Desarrollo de agentes (Agents)\\n- Desarrollo de herramientas (Tools)\\n- Trazabilidad con LangSmith \\n\\n\\n## Resultado\\n\\nEl resultado del proyecto es desplegar un frontal en local, que dado el nombre de un usuario de LinkedIn, se capaz de resumir su perfil, y de mostrar 2 datos interesantes de su perfil.\\n\\n[Aspiracional]\\nEn futuras iteraciones se espera generar tambi√©n de forma autom√°tica un mensaje llamativo para contactar con el por LinkedIn, en base al contenido de su perfil.\\n\\n![img.png](img/img.png)\\n\\n\\n## Instalaci√≥n\\n\\nPara clonar este repositorio y comenzar a experimentar con LangChain, sigue estos pasos:\\n\\n```bash\\ngit clone https://github.com/gmachinromero/exploring-langchain.git\\ncd exploring-langchain\\n```\\n\\nAseg√∫rate de tener instalado Python 3.11+ y pipenv para crear un entorno con todas las dependencias necesarias:\\n\\n```bash\\npipenv install\\n```\\n\\nPara desplegar el frontal debes ejecutar:\\n```bash\\npython app.py\\n```\\n\\nAdicionalmente necesitar√°s los token siguientes en un fichero de configuraci√≥n `.env`:\\n- `OPENAI_API_KEY`\\n- `PROXYCURL_API_KEY`\\n- `TAVILY_API_KEY`\\n- `LANGCHAIN_TRACING_V2`\\n- `LANGCHAIN_ENDPOINT`\\n- `LANGCHAIN_API_KEY`\\n- `LANGCHAIN_PROJECT`\\n\\nDado que el uso de algunas de estas APIs como proxycurl es limitado, se almacenan response tipo en GitHub Gist para poder trabajar de forma continuada sin agotar el n√∫mero de llamadas l√≠mite a la API.\\n\\n## Esquema\\nEl repositorio tiene la siguiente estructura de carpetas:\\n\\n```\\nexploring-langchain/\\n‚îú‚îÄ‚îÄ agents/\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\\n‚îÇ   ‚îî‚îÄ‚îÄ linkedin_lookup_agent.py\\n‚îú‚îÄ‚îÄ parsers/\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\\n‚îÇ   ‚îî‚îÄ‚îÄ output_parser.py\\n‚îú‚îÄ‚îÄ third_party/              \\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\\n‚îÇ   ‚îî‚îÄ‚îÄ linkedin.py\\n‚îú‚îÄ‚îÄ tools/\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\\n‚îÇ   ‚îî‚îÄ‚îÄ tools.py\\n‚îú‚îÄ‚îÄ templates/                 # Plantilla para el frontal\\n‚îÇ   ‚îî‚îÄ‚îÄ index.html\\n‚îú‚îÄ‚îÄ .env                       # Fichero para API_KEYS\\n‚îú‚îÄ‚îÄ .gitignore                 # Archivos a ignorar por Git\\n‚îú‚îÄ‚îÄ app.py                     # Desplegar app con linkedin_summarizer.py\\n‚îú‚îÄ‚îÄ ice_breaker.py             # PoC\\n‚îú‚îÄ‚îÄ linkedin_summarizer.py     # C√≥digo principal\\n‚îú‚îÄ‚îÄ Pipfile                    # Dependencias del proyecto\\n‚îú‚îÄ‚îÄ Pipfile.lock               # Dependencias del proyecto\\n‚îî‚îÄ‚îÄ README.md                  # Descripci√≥n general del proyecto\\n```\\n\\n## Recursos\\n- https://python.langchain.com/v0.2/docs/introduction/\\n- Udemy: LangChain- Develop LLM powered applications with LangChain\\n\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = docs[0]\n",
    "\n",
    "print(type(doc))\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75741ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://raw.githubusercontent.com/gmachinromero/exploring-langchain/refs/heads/master/README.md'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3f559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448dc7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1ad1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2717e9a0",
   "metadata": {},
   "source": [
    "# 3 - Document Splitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fce424b",
   "metadata": {},
   "source": [
    "Una vez que los documentos han sido cargados correctamente, el siguiente paso es **dividir el texto en fragmentos m√°s peque√±os**, adecuados para su posterior vectorizaci√≥n y uso como contexto en el sistema RAG.\n",
    "\n",
    "Esto es necesario porque:\n",
    "\n",
    "- Los modelos de lenguaje tienen un l√≠mite de tokens por entrada (context length).\n",
    "- Dividir bien el texto ayuda a preservar la coherencia sem√°ntica.\n",
    "- Mejora la calidad de la recuperaci√≥n al indexar unidades m√°s espec√≠ficas de informaci√≥n.\n",
    "\n",
    "LangChain proporciona varios **text splitters** que permiten segmentar el contenido de forma flexible. La elecci√≥n del splitter y de sus par√°metros (longitud, solapamiento, m√©todo de segmentaci√≥n) **impacta directamente en la calidad del sistema RAG**.\n",
    "\n",
    "| **Text Splitter**                  | **¬øPara qu√© sirve?**                                                                                                                                                 |\n",
    "|------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `RecursiveCharacterTextSplitter`   | El splitter m√°s vers√°til. Divide el texto intentando respetar estructuras jer√°rquicas (p√°rrafos, frases, palabras). Ideal para mantener coherencia sem√°ntica.        |\n",
    "| `CharacterTextSplitter`            | Divide el texto en fragmentos basados en un n√∫mero fijo de caracteres. M√°s simple que el `Recursive`, √∫til cuando no se necesita segmentaci√≥n inteligente.           |\n",
    "| `TokenTextSplitter`                | Divide el texto en funci√≥n del n√∫mero de tokens, en lugar de caracteres. Muy √∫til si trabajas con l√≠mites de contexto medidos en tokens (como modelos OpenAI).       |\n",
    "| `MarkdownHeaderTextSplitter`       | Dise√±ado espec√≠ficamente para documentos Markdown. Usa los encabezados (`#`, `##`, etc.) como gu√≠as de segmentaci√≥n jer√°rquica.                                      |\n",
    "| `NLTKTextSplitter`                 | Utiliza el tokenizer de NLTK para dividir el texto por frases u oraciones. Requiere instalar NLTK. Apto para NLP cl√°sico o textos con puntuaci√≥n bien estructurada.  |\n",
    "| `SpacyTextSplitter`                | Usa spaCy para dividir por frases u oraciones gramaticales. M√°s preciso que NLTK pero tambi√©n m√°s pesado.                                                            |\n",
    "\n",
    "\n",
    "En esta secci√≥n exploraremos c√≥mo:\n",
    "\n",
    "- Utilizar splitters como `RecursiveCharacterTextSplitter`.\n",
    "- Controlar la longitud (`chunk_size`) y solapamiento de los fragmentos (`chunk_overlap`).\n",
    "- Evaluar si los splits generados mantienen el significado y el contexto necesarios.\n",
    "\n",
    "> La calidad del *splitting* es tan importante como la del *retrieval* ‚Äî fragmentos mal segmentados pueden arruinar incluso los mejores embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d37f8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8946d28e",
   "metadata": {},
   "source": [
    "## 3.1. - RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9e8b7b3",
   "metadata": {},
   "source": [
    "El RecursiveCharacterTextSplitter usa varios niveles de separaci√≥n y adem√°s su l√≥gica es recursiva, con un orden de preferencia de separadores:\n",
    "- Saltos de l√≠nea dobles o simples\n",
    "- Puntuaci√≥n fuerte (. ; :)\n",
    "- Comas y espacios\n",
    "\n",
    "Si no puede dividir con lo anterior, corta por tama√±o fijo (caracteres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f51a73de",
   "metadata": {},
   "source": [
    "![](../img/splitter_chunk_size_overlap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a23f00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=26,\n",
    "    chunk_overlap=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e57dcd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijk',\n",
       " 'lmnopqrstuvwxyzabcdefghij',\n",
       " 'ghijklmnopqrstuvwxyzabcdef',\n",
       " 'cdefghijklmnopq.',\n",
       " 'rstuvwxyz']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijk lmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyzabcdefghijklmnopq. rstuvwxyz'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "588c4200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "388a49ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "564313eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f0094d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54f73072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "73150e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f76d54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P√°ginas del PDF: 22\n",
      "Chunks del PDF: 78\n"
     ]
    }
   ],
   "source": [
    "print(f\"P√°ginas del PDF: {len(pages)}\")\n",
    "print(f\"Chunks del PDF: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc17c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 0\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': '../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck\n",
      "Chunk: 1\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': '../data/docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA ‚Äî he's head TA two years \n",
      "in a row now ‚Äî works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is ‚Äî I guess he's not here  ‚Äî Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs[:2]):\n",
    "    print(f\"Chunk: {i}\")\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c4fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploring-langchain",
   "language": "python",
   "name": "exploring-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
